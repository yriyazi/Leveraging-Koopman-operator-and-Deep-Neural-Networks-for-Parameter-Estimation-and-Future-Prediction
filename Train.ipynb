{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChangeLog\n",
    "\n",
    "1.  waiting to solution settle\n",
    "2.  using only th acceleration data instead of the v and x\n",
    "\n",
    "# Note\n",
    "1.  try to remove the drop out in LSTM\n",
    "2.  BE SURE data for chaotic case in Clean. (Training)\n",
    "3.  Be sure for integration data is noise free.(Integrating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import tqdm\n",
    "import model\n",
    "import utils\n",
    "import loss\n",
    "import deeplearning\n",
    "import torch.nn             as nn\n",
    "import matplotlib.pyplot    as plt\n",
    "import numpy                as np\n",
    "import torch.optim          as optim\n",
    "\n",
    "utils.set_seed(42)\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_horizon      = utils.prediction_horizon\n",
    "prediction_input_size   = utils.prediction_input_size\n",
    "epochs                  = utils.num_epochs\n",
    "_divition_factr         = utils.Noise_division_factor\n",
    "\n",
    "model     = model.Encoder_Decoder().to(device)\n",
    "criterion = loss.custum_loss(alpha=utils.alpha)#torch.nn.MSELoss()\n",
    "optimizer = optim.SGD(\n",
    "                        model.parameters(),\n",
    "                        lr=5e-2,\n",
    "                        momentum=0.9,\n",
    "                        weight_decay=1e-4\n",
    "                        )\n",
    "\n",
    "\n",
    "\n",
    "optimizer_koopman = optim.SGD(\n",
    "                        model.Koopman_operator.parameters(),\n",
    "                        lr=5e-4,\n",
    "                        # momentum=0.9,\n",
    "                        # weight_decay=1e-4\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train - iteration : 1: 100%|██████████| 249/249 [08:14<00:00,  1.99s/it, avg_train_loss_till_current_batch=0.0718, loss_batch=0.0422]\n",
      "  0%|          | 0/1 [08:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory Saved\\.Checkpoints does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m data_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(loaded_data)\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m      5\u001b[0m _Model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGamma =\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnpz_file_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m step_frequency=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnpz_file_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction_input_size\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m cu_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mutils\u001b[38;5;241m.\u001b[39mEigen\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m init=(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnpz_file_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) noise_factor=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_divition_factr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m model, optimizer, report \u001b[38;5;241m=\u001b[39m deeplearning\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m      8\u001b[0m                                                 data_tensor                 \u001b[38;5;241m=\u001b[39m data_tensor[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m100_000\u001b[39m],\n\u001b[0;32m      9\u001b[0m                                                 prediction_input_size       \u001b[38;5;241m=\u001b[39m prediction_input_size,\n\u001b[0;32m     10\u001b[0m                                                 prediction_horizon          \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mprediction_horizon,\n\u001b[0;32m     11\u001b[0m                                                 _divition_factr             \u001b[38;5;241m=\u001b[39m _divition_factr,\n\u001b[0;32m     12\u001b[0m                                                 \n\u001b[0;32m     13\u001b[0m                                                 model                       \u001b[38;5;241m=\u001b[39m model,\n\u001b[0;32m     14\u001b[0m                                                 model_name                  \u001b[38;5;241m=\u001b[39m _Model_name ,\n\u001b[0;32m     15\u001b[0m                                                 epochs                      \u001b[38;5;241m=\u001b[39m epochs,\n\u001b[0;32m     16\u001b[0m                                                 load_saved_model            \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     17\u001b[0m                                                 ckpt_save_freq              \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m ,\n\u001b[0;32m     18\u001b[0m                                                 ckpt_save_path              \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved\u001b[39m\u001b[38;5;124m\"\u001b[39m ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.Checkpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     19\u001b[0m                                                 ckpt_path                   \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved\u001b[39m\u001b[38;5;124m\"\u001b[39m ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.Checkpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mckpt_Gamma =0.50 prediction_input_size=200 cu_loss=False init=(1, 0) noise_factor=1 gammas=0.37-0.29_epoch1.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m) ,\n\u001b[0;32m     20\u001b[0m                                                 report_path                 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved\u001b[39m\u001b[38;5;124m\"\u001b[39m ,\n\u001b[0;32m     21\u001b[0m                                                 \n\u001b[0;32m     22\u001b[0m                                                 criterion                   \u001b[38;5;241m=\u001b[39m criterion,\n\u001b[0;32m     23\u001b[0m                                                 optimizer                   \u001b[38;5;241m=\u001b[39m optimizer,\n\u001b[0;32m     24\u001b[0m                                                 optimizer_koopman           \u001b[38;5;241m=\u001b[39m optimizer_koopman,\n\u001b[0;32m     25\u001b[0m                                                 lr_scheduler                \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     26\u001b[0m                                                 sleep_time                  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     27\u001b[0m                                                 Validation_save_threshold   \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     28\u001b[0m                                                 device                      \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m    ,\n\u001b[0;32m     29\u001b[0m                                                 if_lstm                     \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     30\u001b[0m                                                 )\n",
      "File \u001b[1;32me:\\TAVA\\Koopman\\Leveraging-Koopman-operator-and-Deep-Neural-Networks-for-Parameter-Estimation-and-Future-Prediction\\deeplearning\\Base.py:231\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(data_tensor, prediction_input_size, prediction_horizon, _divition_factr, model, model_name, epochs, load_saved_model, ckpt_save_freq, ckpt_save_path, ckpt_path, report_path, criterion, optimizer, optimizer_koopman, lr_scheduler, sleep_time, Validation_save_threshold, device, if_validation, if_lstm)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# time.sleep(3)\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m ckpt_save_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 231\u001b[0m     save_model(\n\u001b[0;32m    232\u001b[0m         file_path\u001b[38;5;241m=\u001b[39mckpt_save_path,\n\u001b[0;32m    233\u001b[0m         file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mckpt_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    234\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    235\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m    236\u001b[0m     )\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# if utils.scheduler_activate:    \u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m#     lr_schedulerr.step()\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m if_validation:    \n",
      "File \u001b[1;32me:\\TAVA\\Koopman\\Leveraging-Koopman-operator-and-Deep-Neural-Networks-for-Parameter-Estimation-and-Future-Prediction\\deeplearning\\Base.py:70\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(file_path, file_name, model, optimizer)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     state_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstate_dict()\n\u001b[1;32m---> 70\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(state_dict, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(file_path, file_name))\n",
      "File \u001b[1;32mc:\\Users\\YSNfirst\\anaconda3\\envs\\torch3.11\\Lib\\site-packages\\torch\\serialization.py:627\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    624\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 627\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    628\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[0;32m    629\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\YSNfirst\\anaconda3\\envs\\torch3.11\\Lib\\site-packages\\torch\\serialization.py:501\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m container(name_or_buffer)\n",
      "File \u001b[1;32mc:\\Users\\YSNfirst\\anaconda3\\envs\\torch3.11\\Lib\\site-packages\\torch\\serialization.py:472\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory Saved\\.Checkpoints does not exist."
     ]
    }
   ],
   "source": [
    "npz_file_path = os.path.join(\"Duffing_Solution\",\"datasets\",\"gamma=0.37 t_span=(0, 50000) initial_conditions=[1.5, -1.5] step_frequency=010.npy\")\n",
    "loaded_data = utils.read_npz_file(npz_file_path)\n",
    "data_tensor = torch.from_numpy(loaded_data).to(device=device).to(torch.float)\n",
    "\n",
    "_Model_name = f\"Gamma ={npz_file_path.split(' ')[0].split('=')[-1]} step_frequency={npz_file_path.split('.')[-2].split('=')[-1]} {prediction_input_size=} cu_loss={utils.Eigen} init=({npz_file_path.split('[')[-1].split(']')[0]}) noise_factor={_divition_factr}\"\n",
    "\n",
    "model, optimizer, report = deeplearning.train(\n",
    "                                                data_tensor                 = data_tensor[0:100_000],\n",
    "                                                prediction_input_size       = prediction_input_size,\n",
    "                                                prediction_horizon          = utils.prediction_horizon,\n",
    "                                                _divition_factr             = _divition_factr,\n",
    "                                                \n",
    "                                                model                       = model,\n",
    "                                                model_name                  = _Model_name ,\n",
    "                                                epochs                      = epochs,\n",
    "                                                load_saved_model            = False,\n",
    "                                                ckpt_save_freq              = 1 ,\n",
    "                                                ckpt_save_path              = os.path.join(\"Saved\" ,\".Checkpoints\"),\n",
    "                                                ckpt_path                   = os.path.join(\"Saved\" ,\".Checkpoints\",\"ckpt_Gamma =0.50 prediction_input_size=200 cu_loss=False init=(1, 0) noise_factor=1 gammas=0.37-0.29_epoch1.ckpt\") ,\n",
    "                                                report_path                 = \"Saved\" ,\n",
    "                                                \n",
    "                                                criterion                   = criterion,\n",
    "                                                optimizer                   = optimizer,\n",
    "                                                optimizer_koopman           = optimizer_koopman,\n",
    "                                                lr_scheduler                = None,\n",
    "                                                sleep_time                  = None,\n",
    "                                                Validation_save_threshold   = None,\n",
    "                                                device                      = 'cuda'    ,\n",
    "                                                if_lstm                     = True\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # npz_file_path = \"Duffing_Soulution\\datasets\\gamma=0.37 t_span=(0, 100000) initial_conditions=[0, 0.5].npy\"\n",
    "# # loaded_data = utils.read_npz_file(npz_file_path)\n",
    "# # data_tensor = torch.from_numpy(loaded_data).to(device=device).to(torch.float)\n",
    "\n",
    "# # model.load_state_dict(torch.load(os.path.join(directory_path)))\n",
    "# # model.eval()\n",
    "\n",
    "\n",
    "# _divition_factr = 3\n",
    "\n",
    "# with torch.inference_mode():\n",
    "#     Batch = 10\n",
    "#     pred_hor = 1000\n",
    "#     x = data_tensor[Batch*prediction_input_size:(Batch+1)*prediction_input_size]+((2*torch.rand(size=[prediction_input_size],device=device)-1)/(2*_divition_factr))\n",
    "#     y = data_tensor[(Batch+1)*prediction_input_size:(Batch+1)*prediction_input_size+pred_hor]\n",
    "\n",
    "#     prediction_list = torch.zeros(size=[pred_hor]).to(device)\n",
    "\n",
    "#     decoder_hidden, decoder_cell = torch.zeros(size=[2,prediction_input_size],device=device), torch.zeros(size=[2,prediction_input_size],device=device)\n",
    "#     for i in range(pred_hor):\n",
    "#         # prediction = inception.forward(x)\n",
    "#         prediction,(decoder_hidden, decoder_cell) = model.forward(x.unsqueeze(0),decoder_hidden, decoder_cell)\n",
    "#         x =  torch.cat([x[1:],prediction],dim=0)\n",
    "#         prediction_list[i] = prediction\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(20, 6),dpi=300)\n",
    "# plt.plot((prediction_list[:]                                             ).detach().cpu().numpy() , linewidth=2,linestyle='dashed', label=\"Prediction\")\n",
    "# plt.plot((y[:]+(2*torch.rand(size=[pred_hor],device=device)-1)/(2*_divition_factr) ).detach().cpu().numpy() , alpha=0.3, label=\"Noisiy Ground Truth\")\n",
    "# plt.plot((y[:]                                                           ).detach().cpu().numpy() , alpha=0.5, label=\"Ground Truth\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_prediction_list = []\n",
    "_y               = []\n",
    "\n",
    "# model.load_state_dict(torch.load(os.path.join('Saved\\Gamma =0.2 step_frequency=010 prediction_input_size=400 cu_loss=False init=(1.5, -1.5) noise_factor=2.pt')))\n",
    "# model.eval()\n",
    "\n",
    "_divition_factr         = utils.Noise_division_factor\n",
    "\n",
    "for adress     in [ 'Duffing_Soulution\\datasets\\gamma=0.37 t_span=(0, 50000) initial_conditions=[1.5, -1.5] step_frequency=010.npy',\n",
    "                    # 'Duffing_Soulution\\datasets\\gamma=0.2 t_span=(0, 50000) initial_conditions=[0.5, 0.0] step_frequency=010.npy',\n",
    "                    # 'Duffing_Soulution\\datasets\\gamma=0.2 t_span=(0, 50000) initial_conditions=[-0.5, 0.5] step_frequency=010.npy',\n",
    "                        ]:\n",
    "    for _divition_factr in [2,0.5,0.2]:\n",
    "        loaded_data = utils.read_npz_file(adress)\n",
    "        data_tensor = torch.from_numpy(loaded_data).to(device=device).to(torch.float)\n",
    "        with torch.inference_mode():\n",
    "            Batch = 10\n",
    "            pred_hor = 500\n",
    "            x = data_tensor[Batch*prediction_input_size:(Batch+1)*prediction_input_size]+((2*torch.rand(size=[prediction_input_size],device=device)-1)/(2*_divition_factr))\n",
    "            y = data_tensor[(Batch+1)*prediction_input_size:(Batch+1)*prediction_input_size+pred_hor]\n",
    "\n",
    "            prediction_list = torch.zeros(size=[pred_hor]).to(device)\n",
    "\n",
    "            decoder_hidden, decoder_cell = torch.zeros(size=[2,prediction_input_size],device=device), torch.zeros(size=[2,prediction_input_size],device=device)\n",
    "            for i in range(pred_hor):\n",
    "                # prediction = inception.forward(x)\n",
    "                prediction,(decoder_hidden, decoder_cell) = model.forward(x.unsqueeze(0),decoder_hidden, decoder_cell)\n",
    "                x =  torch.cat([x[1:],prediction],dim=0)\n",
    "                prediction_list[i] = prediction\n",
    "\n",
    "        _prediction_list.append(prediction_list)\n",
    "        _y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "def plot_signals(_prediction_list,_y, descriptions,title,_divition_factr=_divition_factr):\n",
    "    \"\"\"\n",
    "    Create three subplots with signals, legends, descriptions, and axis labels.\n",
    "    Parameters:\n",
    "    signals (list of arrays): List of signal arrays to be plotted.\n",
    "    legends (list of str): List of legend labels for each signal.\n",
    "    descriptions (list of str): List of descriptions for each signal.\n",
    "    x_label (str): Label for the x-axis.\n",
    "    y_label (str): Label for the y-axis.\n",
    "    title (str): Title for the entire plot.\n",
    "    \"\"\"\n",
    "    t = np.linspace(0, len(_y[0])/10, len(_y[0]))\n",
    "\n",
    "    num_signals = len(_y)\n",
    "    if num_signals != 3:\n",
    "        raise ValueError(\"Exactly three signals are required.\")\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5),dpi=300)\n",
    "    _divition_factr = [2,0.5,0.2]\n",
    "    for i, ax in enumerate(axes):\n",
    "\n",
    "        ax.plot(t,(_prediction_list[i]).detach().cpu().numpy(), label=\"Prediction\",\n",
    "                linestyle='dashed',\n",
    "                color = 'b',\n",
    "                linewidth=3)\n",
    "        \n",
    "        ax.plot(t,(_y[i]).detach().cpu().numpy(), label=\"Runge-Kutta solution\",\n",
    "                color='g',\n",
    "                alpha=0.7,\n",
    "                linewidth=3,)\n",
    "        \n",
    "        ax.plot(t,(_y[i]+(2*torch.rand(size=[pred_hor],device=device)-1)/(2*_divition_factr[i]) ).detach().cpu().numpy() , label=\"Noisy Runge-Kutta solution\",\n",
    "                color='#e69138',\n",
    "                alpha=0.5)\n",
    "\n",
    "        ax.set_xlabel('Time (s)',fontweight=\"bold\", size=16)\n",
    "        ax.set_ylabel('Acceleration (m/$s^2$)',fontweight=\"bold\", size=16)\n",
    "        ax.set_title(descriptions[i], size=16)\n",
    "        ax.legend(loc='upper right')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        # ax.grid()\n",
    "        # ax.set_xlim(xmin, xmax)\n",
    "        ax.xaxis.set_major_locator(MultipleLocator(5))\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(0.5))\n",
    "\n",
    "        ax.set_ylim(-3, 3) \n",
    "        ax.grid(which=\"major\",alpha=0.6)\n",
    "        ax.grid(which=\"minor\",alpha=1)\n",
    "\n",
    "\n",
    "    plt.suptitle(title,fontweight=\"bold\", size=20)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f\"Images\\Results\\{title}.svg\", format='svg')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "descriptions = [\"a) Base input signal noise amplitude = [-0.25,0.25]\", \"b) noise amplitude = [-1,1]\", \"c) noise amplitude = [-2.5,2.5]\"]\n",
    "x_label = \"Time\"\n",
    "y_label = \"Amplitude\"\n",
    "title   = \"Robustness against Noise gamma=0.37 [N]\"\n",
    "\n",
    "plot_signals(_prediction_list,_y,descriptions, title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Koopman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Koopman_Eigenvalue(\n",
    "                       real_parts           : torch.tensor,\n",
    "                       imaginary_parts      : torch.tensor,\n",
    "                       magnitudes           : torch.tensor,\n",
    "                       title                : str,\n",
    "                       _index               : int = 256,\n",
    "                       DPI                  : int = 400,\n",
    "                       save_image           : bool= None,\n",
    "                       neural_net_name      : str= None,\n",
    "                       dataset_parameters   : str= None,\n",
    "                       save_dir             : str = os.path.join('utils','Plot','Koopman_Eigenvalues')\n",
    "                        )->None:\n",
    "    \n",
    "        real_parts_cpu      = real_parts.cpu().numpy()\n",
    "        imaginary_parts_cpu = imaginary_parts.cpu().numpy()\n",
    "        magnitudes_cpu      = magnitudes.cpu().numpy()\n",
    "        \n",
    "        fig , ax = plt.subplots(1,figsize=(15,10) , dpi=DPI)\n",
    "        \n",
    "        sc = ax.scatter(real_parts_cpu[:_index], imaginary_parts_cpu[:_index], c=magnitudes_cpu[:_index], cmap='viridis', marker='o')\n",
    "        plt.colorbar(sc, label=\"Magnitude\")\n",
    "        \n",
    "        ax.hlines(y=0,xmin=real_parts_cpu.min()     ,xmax=real_parts_cpu.max()      , color='black', linestyle='dashed')\n",
    "        ax.vlines(x=0,ymin=imaginary_parts_cpu.min(),ymax=imaginary_parts_cpu.max() , color='black', linestyle='dashed')\n",
    "        ax.set_xlabel('Real part ($\\mu$)',fontweight=\"bold\", size=16)\n",
    "        ax.set_ylabel('Imaginary part ($\\mu$)',fontweight=\"bold\", size=16)\n",
    "        ax.set_title(f\"neural net = {neural_net_name} index={_index}\",fontweight=\"bold\", size=20)\n",
    "        # ax.set_ylim(-1.25, 1.25) \n",
    "        # ax.set_xlim(-1.25, 1.25) \n",
    "        ax.grid(which=\"major\",alpha=0.6)\n",
    "        ax.grid(which=\"minor\",alpha=1)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        plt.grid(True)\n",
    "        \n",
    "        if save_image:\n",
    "                plt.savefig(f\"Images\\Results\\Koopamn {title}.svg\", format='svg')\n",
    "                \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = torch.linalg.eig(model.Koopman_operator.weight)\n",
    "\n",
    "real_parts = torch.real(eigenvalues)\n",
    "imaginary_parts = torch.imag(eigenvalues)\n",
    "magnitudes = torch.abs(real_parts + 1j * imaginary_parts)\n",
    "\n",
    "Koopman_Eigenvalue(real_parts.detach(),\n",
    "                         imaginary_parts.detach(),\n",
    "                         magnitudes.detach(),\n",
    "                         \"Koopman gamma=0.37\",\n",
    "\n",
    "                         _index         = 1600,\n",
    "                        DPI             = 400,\n",
    "                        save_image      = True,\n",
    "                        neural_net_name = \"CNN-RNN\",\n",
    "                        save_dir = '.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
